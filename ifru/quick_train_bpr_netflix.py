import os
import sys
import numpy as np
import torch
import torch.nn as nn
import pandas as pd
import torch.optim as optim
import time
import random
from sklearn.metrics import roc_auc_score

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from Model.bpr import BPR
from netflix_data_generator import NetflixDataGenerator


class RecBoleDatasetAdapter:
    """é€‚é…å™¨ç±»ï¼Œå°†NetflixDataGeneratoré€‚é…ä¸ºRecBoleæœŸæœ›çš„æ•°æ®é›†æ ¼å¼"""
    
    def __init__(self, data_generator, config):
        self.data_generator = data_generator
        self.config = config
        
        # è®¾ç½®åŸºæœ¬å±æ€§
        self.n_users = data_generator.n_users
        self.n_items = data_generator.n_items
        
        # è®¾ç½®å­—æ®µæ˜ å°„
        self.USER_ID = config.USER_ID_FIELD
        self.ITEM_ID = config.ITEM_ID_FIELD
        
        # åˆ›å»ºå­—æ®µåˆ°æ•°é‡çš„æ˜ å°„
        self._field_num_map = {
            config.USER_ID_FIELD: self.n_users,
            config.ITEM_ID_FIELD: self.n_items,
            'user_id': self.n_users,
            'item_id': self.n_items,
            'user': self.n_users,
            'item': self.n_items
        }
    
    def num(self, field):
        """è¿”å›æŒ‡å®šå­—æ®µçš„æ•°é‡"""
        if field in self._field_num_map:
            return self._field_num_map[field]
        else:
            # é»˜è®¤è¿”å›ç”¨æˆ·æ•°é‡æˆ–ç‰©å“æ•°é‡
            if 'user' in field.lower():
                return self.n_users
            elif 'item' in field.lower():
                return self.n_items
            else:
                return 1  # é»˜è®¤å€¼
    
    def __getattr__(self, name):
        """ä»£ç†å…¶ä»–å±æ€§åˆ°åŸå§‹data_generator"""
        return getattr(self.data_generator, name)


def create_recbole_config(embed_size):
    """åˆ›å»ºå®Œæ•´çš„RecBoleé…ç½®å¯¹è±¡"""
    config_dict = {
        # åŸºæœ¬å­—æ®µ
        'USER_ID_FIELD': 'user_id',
        'ITEM_ID_FIELD': 'item_id', 
        'RATING_FIELD': 'rating',
        'TIME_FIELD': 'timestamp',
        'NEG_PREFIX': 'neg_',
        
        # æ•°æ®å­—æ®µ
        'LABEL_FIELD': 'label',
        'HEAD_ENTITY_ID_FIELD': 'head_id',
        'TAIL_ENTITY_ID_FIELD': 'tail_id',
        'RELATION_ID_FIELD': 'relation_id',
        'ENTITY_ID_FIELD': 'entity_id',
        
        # æ¨¡å‹å‚æ•°
        'embedding_size': embed_size,
        'train_batch_size': 2048,  # Netflixæ•°æ®æ›´å¤§ï¼Œå¢åŠ æ‰¹æ¬¡
        'eval_batch_size': 2048,
        'learning_rate': 0.01,
        'weight_decay': 1e-4,
        'train_neg_sample_args': {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0},
        
        # è®­ç»ƒå‚æ•°
        'epochs': 100,
        'eval_step': 1,
        'stopping_step': 10,
        'checkpoint_dir': './saved',
        'loss_type': 'BPR',
        'eval_type': 'ranking',
        'metrics': ['Recall', 'NDCG'],
        'topk': [5, 10, 20],
        'valid_metric': 'NDCG@10',
        'metric_decimal_place': 4,
        
        # è®¾å¤‡è®¾ç½®  
        'device': 'cuda',
        'use_gpu': True,
        'seed': 2020,
        'reproducibility': True,
        'state': 'INFO',
        
        # æ•°æ®è®¾ç½®
        'field_separator': '\t',
        'seq_separator': ' ',
        'USER_ID': 'user',
        'ITEM_ID': 'item', 
        'NEG_ITEM_ID': 'neg_item'
    }
    
    class SimpleConfig:
        def __init__(self, config_dict):
            for key, value in config_dict.items():
                setattr(self, key, value)
        
        def __getitem__(self, key):
            return getattr(self, key, None)
        
        def __contains__(self, key):
            return hasattr(self, key)
        
        def get(self, key, default=None):
            return getattr(self, key, default)
    
    return SimpleConfig(config_dict)


class QuickBPRTrainer:
    def __init__(self, data_generator):
        # è®¾ç½®BPRæ¨¡å‹å‚æ•° - é’ˆå¯¹Netflixè°ƒæ•´
        self.args = type('Args', (), {
            'embedding_size': 32,    
            'batch_size': 2048,      # Netflixæ•°æ®æ›´å¤§
            'lr': 0.005,             
            'regs': 1e-4,
            'init_std': 0.01         
        })
        
        self.data_generator = data_generator
        
        # åˆ›å»ºå®Œæ•´çš„RecBoleé…ç½®å¯¹è±¡
        config = create_recbole_config(self.args.embedding_size)
        
        # åˆ›å»ºé€‚é…åçš„æ•°æ®é›†
        dataset = RecBoleDatasetAdapter(data_generator, config)
        
        # åˆ›å»ºBPRæ¨¡å‹
        self.model = BPR(config, dataset).cuda()
        self.optimizer = optim.Adam(self.model.parameters(), lr=self.args.lr, weight_decay=self.args.regs)
        
        # å®šä¹‰ä¿å­˜è·¯å¾„
        self.save_path = './Weights/BPR/Quick_BPR_netflix.pth'
        os.makedirs(os.path.dirname(self.save_path), exist_ok=True)
        print(f"æ¨¡å‹å°†ä¿å­˜åˆ°: {self.save_path}")
    
    def get_bpr_scores(self, users, items):
        """è·å–BPRæ¨¡å‹çš„é¢„æµ‹åˆ†æ•°"""
        try:
            # è½¬æ¢ä¸ºtensor
            if not isinstance(users, torch.Tensor):
                users = torch.tensor(users, dtype=torch.long).cuda()
            if not isinstance(items, torch.Tensor):
                items = torch.tensor(items, dtype=torch.long).cuda()
            
            # BPRçš„forwardæ–¹æ³•è¿”å›(user_emb, item_emb)
            output = self.model.forward(users, items)
            if isinstance(output, tuple) and len(output) == 2:
                user_emb, item_emb = output
                scores = torch.sum(user_emb * item_emb, dim=1)
            else:
                scores = output
            return scores
        except Exception as e:
            print(f"è¯„åˆ†è®¡ç®—å‡ºé”™: {e}")
            # å›é€€åˆ°æ‰‹åŠ¨è®¡ç®—
            user_emb = self.model.user_embedding(users)
            item_emb = self.item_embedding(items)
            scores = torch.sum(user_emb * item_emb, dim=1)
            return scores
        
    def train_quick(self, epochs=500):  # Netflixæ•°æ®è¾ƒå¤§ï¼Œè®­ç»ƒæ›´å¤šè½®
        """å¿«é€Ÿè®­ç»ƒBPRæ¨¡å‹"""
        print(f"\nå¼€å§‹å¿«é€Ÿè®­ç»ƒ {epochs} è½®...")
        
        # è®°å½•èµ·å§‹æ—¶é—´
        start_time = time.time()
        
        # è®­ç»ƒå‰æ£€æŸ¥å‚æ•°
        self._print_model_stats("åˆå§‹æ¨¡å‹å‚æ•°")
        
        # è®­ç»ƒå†å²è®°å½•
        train_history = {
            'loss': [],
            'auc': [],
            'best_auc': 0,
            'best_epoch': 0
        }
        
        # è·å–è®­ç»ƒæ•°æ®
        train_users = torch.tensor(self.data_generator.train_users, dtype=torch.long).cuda()
        train_items = torch.tensor(self.data_generator.train_items, dtype=torch.long).cuda()
        train_labels = torch.tensor(self.data_generator.train_labels, dtype=torch.float).cuda()
        
        batch_size = self.args.batch_size
        n_batches = (len(train_users) + batch_size - 1) // batch_size
        
        for epoch in range(epochs):
            epoch_start = time.time()
            total_loss = 0
            
            # éšæœºæ‰“ä¹±æ•°æ®
            perm = torch.randperm(len(train_users))
            train_users_shuffled = train_users[perm]
            train_items_shuffled = train_items[perm]
            train_labels_shuffled = train_labels[perm]
            
            self.model.train()
            
            for batch_idx in range(n_batches):
                start_idx = batch_idx * batch_size
                end_idx = min((batch_idx + 1) * batch_size, len(train_users))
                
                batch_users = train_users_shuffled[start_idx:end_idx]
                batch_items = train_items_shuffled[start_idx:end_idx]
                batch_labels = train_labels_shuffled[start_idx:end_idx]
                
                # ç”Ÿæˆè´Ÿæ ·æœ¬
                neg_items = torch.randint(0, self.data_generator.n_items, (len(batch_users),), dtype=torch.long).cuda()
                
                # æ­£æ ·æœ¬æŸå¤±
                pos_scores = self.get_bpr_scores(batch_users, batch_items)
                neg_scores = self.get_bpr_scores(batch_users, neg_items)
                
                # BPRæŸå¤±
                bpr_loss = -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8))
                
                # æ­£åˆ™åŒ–
                reg_loss = self.args.regs * (
                    torch.norm(self.model.user_embedding.weight) + 
                    torch.norm(self.model.item_embedding.weight)
                )
                
                loss = bpr_loss + reg_loss
                
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
                
                total_loss += loss.item()
            
            avg_loss = total_loss / n_batches
            train_history['loss'].append(avg_loss)
            
            # æ¯10è½®è¯„ä¼°ä¸€æ¬¡
            if epoch % 10 == 0 or epoch == epochs - 1:
                auc = self.evaluate_on_test_set()
                train_history['auc'].append(auc)
                
                if auc > train_history['best_auc']:
                    train_history['best_auc'] = auc
                    train_history['best_epoch'] = epoch
                
                epoch_time = time.time() - epoch_start
                print(f"Epoch {epoch:3d}/{epochs} | Loss: {avg_loss:.4f} | AUC: {auc:.4f} | Time: {epoch_time:.2f}s | Best: {train_history['best_auc']:.4f}@{train_history['best_epoch']}")
            else:
                epoch_time = time.time() - epoch_start
                print(f"Epoch {epoch:3d}/{epochs} | Loss: {avg_loss:.4f} | Time: {epoch_time:.2f}s")
        
        # è®­ç»ƒç»“æŸï¼Œè®¡ç®—æ€»æ—¶é—´
        train_time = time.time() - start_time
        print(f"\nå¿«é€Ÿè®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: {train_time:.2f}ç§’")
        print(f"æœ€ä½³æ€§èƒ½: AUC={train_history['best_auc']:.4f} (ç¬¬{train_history['best_epoch']}è½®)")
        
        # è®­ç»ƒåæ£€æŸ¥å‚æ•°
        self._print_model_stats("è®­ç»ƒåæ¨¡å‹å‚æ•°")
        
        # ä¿å­˜æ¨¡å‹
        print(f"\nä¿å­˜æ¨¡å‹åˆ°: {self.save_path}")
        torch.save(self.model.state_dict(), self.save_path)
        
        # éªŒè¯ä¿å­˜çš„æ¨¡å‹
        self._validate_saved_model()
        
        # ä¿å­˜è®­ç»ƒå†å²
        self.save_training_history(train_history, train_history['best_auc'], train_history['best_epoch'], train_time)
        
        return self.save_path

    def evaluate_on_test_set(self):
        """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹"""
        if len(self.data_generator.test_users) == 0:
            return 0.0
            
        self.model.eval()
        with torch.no_grad():
            test_users = torch.tensor(self.data_generator.test_users, dtype=torch.long).cuda()
            test_items = torch.tensor(self.data_generator.test_items, dtype=torch.long).cuda()
            test_labels = self.data_generator.test_labels
            
            # æ‰¹é‡é¢„æµ‹
            batch_size = 2048
            all_scores = []
            
            for i in range(0, len(test_users), batch_size):
                batch_users = test_users[i:i+batch_size]
                batch_items = test_items[i:i+batch_size]
                scores = self.get_bpr_scores(batch_users, batch_items)
                all_scores.append(scores.cpu().numpy())
            
            pred_scores = np.concatenate(all_scores)
            auc = roc_auc_score(test_labels, pred_scores)
            
        return auc

    def save_training_history(self, history, best_auc, best_epoch, total_time):
        """ä¿å­˜è®­ç»ƒå†å²"""
        result_dir = './results'
        os.makedirs(result_dir, exist_ok=True)
        
        result_file = f'{result_dir}/bpr_netflix_training_history.json'
        
        result_data = {
            'model': 'BPR',
            'dataset': 'netflix',
            'embedding_size': self.args.embedding_size,
            'batch_size': self.args.batch_size,
            'learning_rate': self.args.lr,
            'regularization': self.args.regs,
            'total_time': total_time,
            'best_auc': best_auc,
            'best_epoch': best_epoch,
            'train_loss': history['loss'],
            'test_auc': history['auc'],
            'data_stats': {
                'n_users': self.data_generator.n_users,
                'n_items': self.data_generator.n_items,
                'n_train': len(self.data_generator.train),
                'n_test': len(self.data_generator.test)
            }
        }
        
        import json
        with open(result_file, 'w') as f:
            json.dump(result_data, f, indent=2)
        
        print(f"è®­ç»ƒå†å²ä¿å­˜åˆ°: {result_file}")
    
    def _print_model_stats(self, title):
        """æ‰“å°æ¨¡å‹å‚æ•°ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n{title}:")
        user_weights = self.model.user_embedding.weight.data
        item_weights = self.model.item_embedding.weight.data
        
        print(f"ç”¨æˆ·åµŒå…¥: mean={user_weights.mean():.6f}, std={user_weights.std():.6f}")
        print(f"ç‰©å“åµŒå…¥: mean={item_weights.mean():.6f}, std={item_weights.std():.6f}")
    
    def _validate_saved_model(self):
        """éªŒè¯ä¿å­˜çš„æ¨¡å‹"""
        try:
            # åˆ›å»ºæ–°æ¨¡å‹å®ä¾‹
            config = create_recbole_config(self.args.embedding_size)
            dataset = RecBoleDatasetAdapter(self.data_generator, config)
            test_model = BPR(config, dataset).cuda()
            
            # åŠ è½½ä¿å­˜çš„æƒé‡
            test_model.load_state_dict(torch.load(self.save_path))
            print("âœ… æ¨¡å‹éªŒè¯æˆåŠŸï¼Œæƒé‡åŠ è½½æ­£å¸¸")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {e}")


def main():
    # è®¾ç½®éšæœºç§å­
    np.random.seed(1024)
    torch.manual_seed(1024)
    torch.cuda.manual_seed(1024)
    
    print("="*80)
    print("è®­ç»ƒBPRæ¨¡å‹ç”¨äºIFRUæµ‹è¯• (Netflixæ•°æ®é›†)")
    print("="*80)
    
    # åˆ›å»ºå®Œæ•´çš„argså¯¹è±¡
    args = type('Args', (), {
        'embed_size': 32,
        'batch_size': 2048,
        'data_path': '/data/IFRU-main/Data/',
        'dataset': 'netflix',
        'attack': '',
        'data_type': 'full',
        'A_split': False,
        'A_n_fold': 100,
        'keep_prob': 1.0,
        'gcn_layers': 2,
        'dropout': False,
        'pretrain': 0,
        'lr': 0.005,
        'regs': 1e-4,
        'init_std': 0.01
    })
    
    try:
        # åŠ è½½æ•°æ®
        print("åŠ è½½Netflixæ•°æ®é›†...")
        data_path = '/data/IFRU-main/Data/netflix'
        data_generator = NetflixDataGenerator(args, path=data_path)
        data_generator.set_train_mode(args.data_type)
        
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
        print(f"ç”¨æˆ·æ•°: {data_generator.n_users}")
        print(f"ç‰©å“æ•°: {data_generator.n_items}")
        print(f"è®­ç»ƒæ ·æœ¬: {len(data_generator.train)}")
        print(f"æµ‹è¯•æ ·æœ¬: {len(data_generator.test)}")
        
        # åˆ›å»ºè®­ç»ƒå™¨å¹¶è®­ç»ƒ
        print("\nåˆ›å»ºBPRè®­ç»ƒå™¨...")
        trainer = QuickBPRTrainer(data_generator)
        
        # å¼€å§‹è®­ç»ƒ
        saved_model_path = trainer.train_quick(epochs=500)
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"æ¨¡å‹ä¿å­˜è·¯å¾„: {saved_model_path}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    os.environ["CUDA_VISIBLE_DEVICES"] = '0'
    main()