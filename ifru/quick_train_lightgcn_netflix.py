import os
import sys
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import time as time_module  # é¿å…åç§°å†²çª
from sklearn.metrics import roc_auc_score

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from utility.load_data import *
from Model.Lightgcn import LightGCN
from utility.compute import *
from netflix_data_generator import NetflixDataGenerator


class NetflixLightGCNAdapter:
    """å°†NetflixDataGeneratoré€‚é…ä¸ºLightGCNæœŸæœ›çš„Data_for_LightGCNæ ¼å¼"""
    
    def __init__(self, netflix_generator):
        self.netflix_generator = netflix_generator
        
        # å¤åˆ¶åŸºæœ¬å±æ€§
        self.n_users = netflix_generator.n_users
        self.n_items = netflix_generator.n_items
        self.train_users = netflix_generator.train_users
        self.train_items = netflix_generator.train_items
        self.train_labels = netflix_generator.train_labels
        self.test_users = netflix_generator.test_users
        self.test_items = netflix_generator.test_items  
        self.test_labels = netflix_generator.test_labels
        
        # åˆ›å»ºå›¾ç»“æ„
        self.create_graph_structure()
        
        print(f"âœ… LightGCNé€‚é…å™¨åˆ›å»ºæˆåŠŸ")
        print(f"å›¾ç»“æ„: {self.Graph.shape}")
        print(f"ç¨€ç–å›¾éé›¶å…ƒç´ : {self.Graph.nnz}")
    
    def create_graph_structure(self):
        """åˆ›å»ºç”¨æˆ·-ç‰©å“äºŒåˆ†å›¾"""
        print("å¼€å§‹åˆ›å»ºå›¾ç»“æ„...")
        
        # ç”¨æˆ·-ç‰©å“äº¤äº’çŸ©é˜µ
        user_item_matrix = sp.coo_matrix(
            (np.ones(len(self.train_users)), 
             (self.train_users, self.train_items)),
            shape=(self.n_users, self.n_items)
        )
        
        print(f"ç”¨æˆ·-ç‰©å“äº¤äº’çŸ©é˜µ: {user_item_matrix.shape}, éé›¶å…ƒç´ : {user_item_matrix.nnz}")
        
        # åˆ›å»ºäºŒåˆ†å›¾é‚»æ¥çŸ©é˜µ
        # [0,     R]
        # [R^T,   0]
        zero_user = sp.coo_matrix((self.n_users, self.n_users))
        zero_item = sp.coo_matrix((self.n_items, self.n_items))
        
        # æ„å»ºå®Œæ•´çš„é‚»æ¥çŸ©é˜µ
        adj_mat = sp.bmat([
            [zero_user, user_item_matrix],
            [user_item_matrix.T, zero_item]
        ], format='coo')
        
        print(f"é‚»æ¥çŸ©é˜µ: {adj_mat.shape}, éé›¶å…ƒç´ : {adj_mat.nnz}")
        
        # å½’ä¸€åŒ–
        adj_mat = adj_mat.tocsr()  # è½¬æ¢ä¸ºCSRä»¥ä¾¿è®¡ç®—
        rowsum = np.array(adj_mat.sum(1)).flatten()
        
        # å¤„ç†é›¶åº¦æ•°èŠ‚ç‚¹
        d_inv = np.power(rowsum, -0.5)
        d_inv[np.isinf(d_inv)] = 0.0
        d_inv[np.isnan(d_inv)] = 0.0
        d_mat_inv = sp.diags(d_inv)
        
        norm_adj = d_mat_inv.dot(adj_mat).dot(d_mat_inv)
        self.Graph = norm_adj.tocsr()
        
        print(f"å½’ä¸€åŒ–åå›¾: {self.Graph.shape}, éé›¶å…ƒç´ : {self.Graph.nnz}")
        
        # åˆ›å»ºç¨€ç–tensorç‰ˆæœ¬ï¼ˆç”¨äºGPUï¼‰- å…³é”®ä¿®å¤ï¼
        # è½¬æ¢ä¸ºCOOæ ¼å¼ä»¥è·å–indices
        coo_graph = self.Graph.tocoo()
        
        indices = torch.from_numpy(
            np.vstack([coo_graph.row, coo_graph.col]).astype(np.int64)
        )
        values = torch.from_numpy(coo_graph.data.astype(np.float32))
        shape = coo_graph.shape
        
        # åˆ›å»ºç¨€ç–å¼ é‡å¹¶ç§»åˆ°GPU
        self.sparse_graph = torch.sparse.FloatTensor(indices, values, shape).cuda()
        print(f"ç¨€ç–å¼ é‡åˆ›å»ºæˆåŠŸå¹¶ç§»åˆ°GPU: {shape}")
    
    def getSparseGraph(self):
        """è¿”å›ç¨€ç–å›¾ï¼ˆå…¼å®¹LightGCNæ¥å£ï¼‰"""
        return self.sparse_graph
    
    def set_train_mode(self, mode):
        """å…¼å®¹æ¥å£"""
        print(f"è®¾ç½®è®­ç»ƒæ¨¡å¼: {mode}")
        pass
    
    def __getattr__(self, name):
        """ä»£ç†å…¶ä»–å±æ€§åˆ°åŸå§‹netflix_generator"""
        return getattr(self.netflix_generator, name)


class CustomLightGCN(nn.Module):
    """è‡ªå®šä¹‰LightGCNæ¨¡å‹ï¼Œç¡®ä¿æ­£ç¡®ä½¿ç”¨æˆ‘ä»¬çš„ç¨€ç–å›¾"""
    
    def __init__(self, args, dataset):
        super(CustomLightGCN, self).__init__()
        
        self.n_users = dataset.n_users
        self.n_items = dataset.n_items
        self.latent_dim = args.embed_size
        self.n_layers = args.gcn_layers
        self.keep_prob = args.keep_prob
        self.A_split = args.A_split
        self.dropout = args.dropout
        
        # è·å–ç¨€ç–å›¾
        self.Graph = dataset.getSparseGraph()
        print(f"LightGCNæ¥æ”¶åˆ°çš„å›¾ç±»å‹: {type(self.Graph)}")
        
        # åˆå§‹åŒ–åµŒå…¥
        self.embedding_user = nn.Embedding(self.n_users, self.latent_dim)
        self.embedding_item = nn.Embedding(self.n_items, self.latent_dim)
        
        # åˆå§‹åŒ–æƒé‡
        self.f = nn.Sigmoid()
        self.__init_weight()
    
    def __init_weight(self):
        """åˆå§‹åŒ–æƒé‡"""
        nn.init.normal_(self.embedding_user.weight, std=0.01)
        nn.init.normal_(self.embedding_item.weight, std=0.01)
        print('use NORMAL distribution initilizer')
    
    def __dropout_x(self, x, keep_prob):
        """Dropout"""
        size = x.size()
        index = x.indices().t()
        values = x.values()
        random_index = torch.rand(len(values)) + keep_prob
        random_index = random_index.int().bool()
        index = index[random_index]
        values = values[random_index]/keep_prob
        g = torch.sparse.FloatTensor(index.t(), values, size)
        return g
    
    def __dropout(self, keep_prob):
        """å¯¹å›¾è¿›è¡Œdropout"""
        if self.A_split:
            graph = []
            for g in self.Graph:
                graph.append(self.__dropout_x(g, keep_prob))
        else:
            graph = self.__dropout_x(self.Graph, keep_prob)
        return graph
    
    def computer(self):
        """å›¾å·ç§¯ä¼ æ’­"""
        users_emb = self.embedding_user.weight
        items_emb = self.embedding_item.weight
        all_emb = torch.cat([users_emb, items_emb])
        
        embs = [all_emb]
        
        if self.dropout:
            if self.training:
                g_droped = self.__dropout(self.keep_prob)
            else:
                g_droped = self.Graph        
        else:
            g_droped = self.Graph
        
        for layer in range(self.n_layers):
            if self.A_split:
                temp_emb = []
                for f in range(len(g_droped)):
                    temp_emb.append(torch.sparse.mm(g_droped[f], all_emb))
                side_emb = torch.cat(temp_emb, dim=0)
                all_emb = side_emb
            else:
                # ç¡®ä¿ä½¿ç”¨PyTorchç¨€ç–çŸ©é˜µä¹˜æ³•
                all_emb = torch.sparse.mm(g_droped, all_emb)
                
            embs.append(all_emb)
        
        embs = torch.stack(embs, dim=1)
        light_out = torch.mean(embs, dim=1)
        users, items = torch.split(light_out, [self.n_users, self.n_items])
        
        return users, items
    
    def getUsersRating(self, users):
        """è·å–ç”¨æˆ·å¯¹æ‰€æœ‰ç‰©å“çš„è¯„åˆ†"""
        all_users, all_items = self.computer()
        users_emb = all_users[users.long()]
        items_emb = all_items
        rating = self.f(torch.matmul(users_emb, items_emb.t()))
        return rating
    
    def getEmbedding(self, users, pos_items, neg_items):
        """è·å–åµŒå…¥"""
        all_users, all_items = self.computer()
        users_emb = all_users[users]
        pos_emb = all_items[pos_items]
        neg_emb = all_items[neg_items]
        users_emb_ego = self.embedding_user(users)
        pos_emb_ego = self.embedding_item(pos_items)
        neg_emb_ego = self.embedding_item(neg_items)
        return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego
    
    def bpr_loss(self, users, pos, neg):
        """BPRæŸå¤±"""
        (users_emb, pos_emb, neg_emb, 
        userEmb0, posEmb0, negEmb0) = self.getEmbedding(users.long(), pos.long(), neg.long())
        
        reg_loss = (1/2)*(userEmb0.norm(2).pow(2) + 
                         posEmb0.norm(2).pow(2)  +
                         negEmb0.norm(2).pow(2))/float(len(users))
        
        pos_scores = torch.mul(users_emb, pos_emb)
        pos_scores = torch.sum(pos_scores, dim=1)
        neg_scores = torch.mul(users_emb, neg_emb)
        neg_scores = torch.sum(neg_scores, dim=1)
        
        loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))
        
        return loss, reg_loss
       
    def forward(self, users, items):
        """å‰å‘ä¼ æ’­"""
        all_users, all_items = self.computer()
        users_emb = all_users[users]
        items_emb = all_items[items]
        inner_pro = torch.mul(users_emb, items_emb)
        gamma = torch.sum(inner_pro, dim=1)
        return gamma


class QuickTrainer:
    def __init__(self, data_generator):
        # è®¾ç½®æ›´å°çš„æ¨¡å‹å‚æ•°ä»¥åŠ é€Ÿè®­ç»ƒ - é’ˆå¯¹Netflixè°ƒæ•´
        self.args = type('Args', (), {
            'embed_size': 32,
            'batch_size': 2048,      # Netflixæ•°æ®è¾ƒå¤§
            'gcn_layers': 2,
            'lr': 0.005,
            'regs': 1e-4,
            'keep_prob': 1.0,
            'A_n_fold': 100,
            'A_split': False,
            'dropout': False,
            'pretrain': 0,
            'init_std': 0.01
        })
        
        self.data_generator = data_generator
        
        # ä½¿ç”¨è‡ªå®šä¹‰LightGCNæ¨¡å‹
        print("åˆå§‹åŒ–è‡ªå®šä¹‰LightGCNæ¨¡å‹...")
        self.model = CustomLightGCN(self.args, dataset=data_generator).cuda()
        self.optimizer = optim.Adam(self.model.parameters(), lr=self.args.lr)
        
        # å®šä¹‰ä¿å­˜è·¯å¾„
        self.save_path = './Weights/LightGCN/Quick_LightGCN_netflix.pth'
        os.makedirs(os.path.dirname(self.save_path), exist_ok=True)
        print(f"æ¨¡å‹å°†ä¿å­˜åˆ°: {self.save_path}")
        
    def train_quick(self, epochs=10):  # Netflixæ•°æ®è¾ƒå¤§ï¼Œé€‚å½“å¢åŠ è®­ç»ƒè½®æ•°
        """å¿«é€Ÿè®­ç»ƒå‡ ä¸ªepoch"""
        print(f"\nå¼€å§‹å¿«é€Ÿè®­ç»ƒ {epochs} è½®...")
        
        # è®°å½•èµ·å§‹æ—¶é—´
        start_time = time_module.time()
        
        # è®­ç»ƒå‰æ£€æŸ¥å‚æ•°
        self._print_model_stats("åˆå§‹æ¨¡å‹å‚æ•°")
        
        # è®­ç»ƒå†å²è®°å½•
        train_history = {
            'loss': [],
            'auc': [],
            'best_auc': 0,
            'best_epoch': 0
        }
        
        # è·å–è®­ç»ƒæ•°æ®
        train_users = torch.tensor(self.data_generator.train_users, dtype=torch.long).cuda()
        train_items = torch.tensor(self.data_generator.train_items, dtype=torch.long).cuda()
        train_labels = torch.tensor(self.data_generator.train_labels, dtype=torch.float).cuda()
        
        batch_size = self.args.batch_size
        n_batches = (len(train_users) + batch_size - 1) // batch_size
        
        for epoch in range(epochs):
            epoch_start = time_module.time()
            total_loss = 0
            
            # éšæœºæ‰“ä¹±æ•°æ®
            perm = torch.randperm(len(train_users))
            train_users_shuffled = train_users[perm]
            train_items_shuffled = train_items[perm]
            train_labels_shuffled = train_labels[perm]
            
            self.model.train()
            
            for batch_idx in range(n_batches):
                start_idx = batch_idx * batch_size
                end_idx = min((batch_idx + 1) * batch_size, len(train_users))
                
                batch_users = train_users_shuffled[start_idx:end_idx]
                batch_items = train_items_shuffled[start_idx:end_idx]
                batch_labels = train_labels_shuffled[start_idx:end_idx]
                
                # ç”Ÿæˆè´Ÿæ ·æœ¬
                neg_items = torch.randint(0, self.data_generator.n_items, (len(batch_users),), dtype=torch.long).cuda()
                
                try:
                    # å‰å‘ä¼ æ’­
                    all_users, all_items = self.model.computer()  # è‡ªå®šä¹‰LightGCNçš„computeræ–¹æ³•
                    
                    # è·å–åµŒå…¥
                    pos_user_emb = all_users[batch_users]
                    pos_item_emb = all_items[batch_items]
                    neg_item_emb = all_items[neg_items]
                    
                    # è®¡ç®—åˆ†æ•°
                    pos_scores = torch.sum(pos_user_emb * pos_item_emb, dim=1)
                    neg_scores = torch.sum(pos_user_emb * neg_item_emb, dim=1)
                    
                    # BPRæŸå¤±
                    bpr_loss = -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8))
                    
                    # æ­£åˆ™åŒ–æŸå¤±
                    reg_loss = self.args.regs * (
                        torch.norm(pos_user_emb) + 
                        torch.norm(pos_item_emb) + 
                        torch.norm(neg_item_emb)
                    ) / len(batch_users)
                    
                    loss = bpr_loss + reg_loss
                    
                    self.optimizer.zero_grad()
                    loss.backward()
                    self.optimizer.step()
                    
                    total_loss += loss.item()
                    
                except Exception as e:
                    print(f"æ‰¹æ¬¡ {batch_idx} è®­ç»ƒå‡ºé”™: {e}")
                    # æ£€æŸ¥å›¾çš„ç±»å‹
                    graph = self.data_generator.getSparseGraph()
                    print(f"å›¾ç±»å‹: {type(graph)}")
                    print(f"å›¾è®¾å¤‡: {graph.device if hasattr(graph, 'device') else 'N/A'}")
                    raise e
            
            avg_loss = total_loss / n_batches
            train_history['loss'].append(avg_loss)
            
            # æ¯è½®éƒ½è¯„ä¼°ï¼ˆå› ä¸ºæ€»è½®æ•°è¾ƒå°‘ï¼‰
            auc = self.evaluate_on_test_set()
            train_history['auc'].append(auc)
            
            if auc > train_history['best_auc']:
                train_history['best_auc'] = auc
                train_history['best_epoch'] = epoch
            
            epoch_time = time_module.time() - epoch_start
            print(f"Epoch {epoch:2d}/{epochs} | Loss: {avg_loss:.4f} | AUC: {auc:.4f} | Time: {epoch_time:.2f}s | Best: {train_history['best_auc']:.4f}@{train_history['best_epoch']}")
        
        # è®­ç»ƒç»“æŸï¼Œè®¡ç®—æ€»æ—¶é—´
        train_time = time_module.time() - start_time
        print(f"\nå¿«é€Ÿè®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: {train_time:.2f}ç§’")
        print(f"æœ€ä½³æ€§èƒ½: AUC={train_history['best_auc']:.4f} (ç¬¬{train_history['best_epoch']}è½®)")
        
        # è®­ç»ƒåæ£€æŸ¥å‚æ•°
        self._print_model_stats("è®­ç»ƒåæ¨¡å‹å‚æ•°")
        
        # ä¿å­˜æ¨¡å‹
        print(f"\nä¿å­˜æ¨¡å‹åˆ°: {self.save_path}")
        torch.save(self.model.state_dict(), self.save_path)
        
        # éªŒè¯ä¿å­˜çš„æ¨¡å‹
        self._validate_saved_model()
        
        # ä¿å­˜è®­ç»ƒå†å²
        self.save_training_history(train_history, train_history['best_auc'], train_history['best_epoch'], train_time)
        
        return self.save_path

    def evaluate_on_test_set(self):
        """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹"""
        if len(self.data_generator.test_users) == 0:
            return 0.0
            
        self.model.eval()
        with torch.no_grad():
            try:
                # è·å–æ‰€æœ‰åµŒå…¥
                all_users, all_items = self.model.computer()
                
                test_users = torch.tensor(self.data_generator.test_users, dtype=torch.long).cuda()
                test_items = torch.tensor(self.data_generator.test_items, dtype=torch.long).cuda()
                test_labels = self.data_generator.test_labels
                
                # æ‰¹é‡é¢„æµ‹
                batch_size = 2048
                all_scores = []
                
                for i in range(0, len(test_users), batch_size):
                    batch_users = test_users[i:i+batch_size]
                    batch_items = test_items[i:i+batch_size]
                    
                    user_emb = all_users[batch_users]
                    item_emb = all_items[batch_items]
                    scores = torch.sum(user_emb * item_emb, dim=1)
                    all_scores.append(scores.cpu().numpy())
                
                pred_scores = np.concatenate(all_scores)
                auc = roc_auc_score(test_labels, pred_scores)
                
            except Exception as e:
                print(f"è¯„ä¼°æ—¶å‡ºé”™: {e}")
                return 0.0
            
        return auc

    def save_training_history(self, history, best_auc, best_epoch, total_time):
        """ä¿å­˜è®­ç»ƒå†å²"""
        result_dir = './results'
        os.makedirs(result_dir, exist_ok=True)
        
        result_file = f'{result_dir}/lightgcn_netflix_training_history.json'
        
        result_data = {
            'model': 'LightGCN',
            'dataset': 'netflix',
            'embedding_size': self.args.embed_size,
            'gcn_layers': self.args.gcn_layers,
            'batch_size': self.args.batch_size,
            'learning_rate': self.args.lr,
            'regularization': self.args.regs,
            'total_time': total_time,
            'best_auc': best_auc,
            'best_epoch': best_epoch,
            'train_loss': history['loss'],
            'test_auc': history['auc'],
            'data_stats': {
                'n_users': self.data_generator.n_users,
                'n_items': self.data_generator.n_items,
                'n_train': len(self.data_generator.train),
                'n_test': len(self.data_generator.test)
            }
        }
        
        import json
        with open(result_file, 'w') as f:
            json.dump(result_data, f, indent=2)
        
        print(f"è®­ç»ƒå†å²ä¿å­˜åˆ°: {result_file}")
    
    def _print_model_stats(self, title):
        """æ‰“å°æ¨¡å‹å‚æ•°ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n{title}:")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰åµŒå…¥å±‚
        if hasattr(self.model, 'embedding_user') and hasattr(self.model, 'embedding_item'):
            user_weights = self.model.embedding_user.weight.data
            item_weights = self.model.embedding_item.weight.data
            
            print(f"ç”¨æˆ·åµŒå…¥: mean={user_weights.mean():.6f}, std={user_weights.std():.6f}")
            print(f"ç‰©å“åµŒå…¥: mean={item_weights.mean():.6f}, std={item_weights.std():.6f}")
        else:
            print("æ¨¡å‹å‚æ•°ä¿¡æ¯ä¸å¯ç”¨")
    
    def _validate_saved_model(self):
        """éªŒè¯ä¿å­˜çš„æ¨¡å‹"""
        try:
            # åˆ›å»ºæ–°æ¨¡å‹å®ä¾‹
            test_model = CustomLightGCN(self.args, dataset=self.data_generator).cuda()
            
            # åŠ è½½ä¿å­˜çš„æƒé‡
            test_model.load_state_dict(torch.load(self.save_path))
            print("âœ… æ¨¡å‹éªŒè¯æˆåŠŸï¼Œæƒé‡åŠ è½½æ­£å¸¸")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {e}")


def main():
    # è®¾ç½®éšæœºç§å­
    np.random.seed(1024)
    torch.manual_seed(1024)
    torch.cuda.manual_seed(1024)
    
    print("="*80)
    print("å¿«é€Ÿè®­ç»ƒLightGCNå°æ¨¡å‹ç”¨äºNetflix IFRUæµ‹è¯•")
    print("="*80)
    
    # åˆ›å»ºå®Œæ•´çš„argså¯¹è±¡
    args = type('Args', (), {
        'embed_size': 32,
        'batch_size': 2048,
        'data_path': '/data/IFRU-main/Data/',
        'dataset': 'netflix',
        'attack': '',
        'data_type': 'full',
        'A_split': False,
        'A_n_fold': 100,
        'keep_prob': 1.0,
        'gcn_layers': 2,
        'dropout': False,
        'pretrain': 0,
        'lr': 0.005,
        'regs': 1e-4,
        'init_std': 0.01
    })
    
    try:
        # åŠ è½½æ•°æ®
        print("åŠ è½½Netflixæ•°æ®é›†...")
        data_path = '/data/IFRU-main/Data/netflix'
        netflix_generator = NetflixDataGenerator(args, path=data_path)
        
        # åˆ›å»ºLightGCNé€‚é…å™¨
        print("åˆ›å»ºLightGCNé€‚é…å™¨...")
        data_generator = NetflixLightGCNAdapter(netflix_generator)
        data_generator.set_train_mode(args.data_type)
        
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
        print(f"ç”¨æˆ·æ•°: {data_generator.n_users}")
        print(f"ç‰©å“æ•°: {data_generator.n_items}")
        print(f"è®­ç»ƒæ ·æœ¬: {len(data_generator.train_users)}")
        print(f"æµ‹è¯•æ ·æœ¬: {len(data_generator.test_users)}")
        
        # åˆ›å»ºè®­ç»ƒå™¨å¹¶è®­ç»ƒ
        print("\nåˆ›å»ºLightGCNè®­ç»ƒå™¨...")
        trainer = QuickTrainer(data_generator)
        
        # å¼€å§‹è®­ç»ƒ
        saved_model_path = trainer.train_quick(epochs=1000)
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"æ¨¡å‹ä¿å­˜è·¯å¾„: {saved_model_path}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    os.environ["CUDA_VISIBLE_DEVICES"] = '0'
    main()